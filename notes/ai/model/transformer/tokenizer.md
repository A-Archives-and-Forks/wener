---
title: Tokenizer
---

# Tokenizer

- openai
  - gpt2
    - vocabe 50257
  - r50k_base
    - vocabe 50257
  - p50k_base
    - vocabe 50281
  - p50k_edit
    - vocabe 50283
    - Codex
  - cl100k_base
    - vocabe 100276
  - o200k_base
    - vocabe 200018
  - o200k_harmony
    - vocabe 201088
    - 在 c200k_base 上增加了额外的特殊 token
- 参考
  - openai/tiktoken https://github.com/openai/tiktoken/blob/main/tiktoken_ext/openai_public.py
