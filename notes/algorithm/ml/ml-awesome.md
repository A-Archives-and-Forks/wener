---
title: ML Awesome
---

# Machine Learning Awesome

- [tonybeltramelli/pix2code](https://github.com/tonybeltramelli/pix2code)
  - GUI Screenshot -> Code

## Learn

- [LabML Neural Networks](https://nn.labml.ai/)
  - PyTorch
- [Reinforcement Learning: Theory and Algorithms](https://rltheorybook.github.io/)

## Framework

- [flashlight/flashlight](https://github.com/flashlight/flashlight)
  - C++ standalone library for machine learning
  - from Facebook AI Research Speech team, creators of Torch and Deep Speech
- [arrayfire/arrayfire](https://github.com/arrayfire/arrayfire)
  - general purpose GPU library
- [tensorflow/lingvo](https://github.com/tensorflow/lingvo)
  - building sequence models neural networks in Tensorflow
  - ASR, MT

## Language
- [JetBrains/KotlinDL](https://github.com/JetBrains/KotlinDL)
  - Kotlin DSL for ML

## Intrested

- [ZHKKKe/MODNet](https://github.com/ZHKKKe/MODNet)
  - 背景消除

## Models

- BERT
- Tacotron
- Wavenet/Waveglow/WaveRNN
- Eesen, Espresso, Kaldi, Wav2letter, NeMo
- VGG’16
- VGG’19
- ResNet50
- ResNet101
- ResNet152
- ResNet50v2
- ResNet101v2
- ResNet152v2
- MobileNet
- MobileNetv2
- https://modelplace.ai/models

## STT

- [cmusphinx](https://cmusphinx.github.io/)
  - 工作已经开始转移到 Kaldi, Vosk
  - [cmusphinx/pocketsphinx](https://github.com/cmusphinx/pocketsphinx)
- [alphacep/vosk-api](https://github.com/alphacep/vosk-api)
  - Offline speech recognition API
  - Python, Java, C#, Node
  - 支持中文
  - [alphacep/vosk-asterisk](https://github.com/alphacep/vosk-asterisk)
    - res-speech-vosk - Asterisk 集成
- [alphacep/vosk-android-demo](https://github.com/alphacep/vosk-android-demo)
  - Offline speech recognition for Android with Vosk library
- [kaldi-asr/kaldi](https://github.com/kaldi-asr/kaldi)
  - Speech Recognition Toolkit
- [julius-speech/julius](https://github.com/julius-speech/julius)
  - Open-Source Large Vocabulary Continuous Speech Recognition Engine
- [daanzu/kaldi-active-grammar](https://github.com/daanzu/kaldi-active-grammar)
  - Python Kaldi speech recognition with grammars that can be set active/inactive dynamically at decode-time
- [espnet/espnet](https://github.com/espnet/espnet)
  - End-to-End Speech Processing Toolkit
- [flashlight/wav2letter](https://github.com/flashlight/wav2letter)
  - Facebook AI Research's Automatic Speech Recognition Toolkit
- [Nvidia/NeMo](https://github.com/Nvidia/NeMo)
  - toolkit for conversational AI
  - ASR, NLP, TTS
- [PaddlePaddle/DeepSpeech](https://github.com/PaddlePaddle/DeepSpeech)
  - ASR toolkit
  - 百度 [Deep Speech: Scaling up end-to-end speech recognition](https://arxiv.org/abs/1412.5567)
- [mozilla/DeepSpeech](https://github.com/mozilla/DeepSpeech)
  - 基于 Tensorflow
- [arjo129/uSpeech](https://github.com/arjo129/uSpeech)
  - Speech recognition toolkit for the arduino
- [coqui-ai](https://github.com/coqui-ai)
  - TTS
  - STT - 没有中文模型
- [synesthesiam/voice2json](https://github.com/synesthesiam/voice2json)
  - 命令行工具
  - 中文模型基于 pocketsphinx
  - [HN](https://news.ycombinator.com/item?id=27235970)

**术语**

| abbr | mean                          | desc |
| ---- | ----------------------------- | ---- |
| ASR  | Automatic Speech Recognition  |
| TTS  | Text-to-speech                |
| SE   | Speech enhancement/separation |
| ST   | Speech Translation            |
| MT   | Machine Translation           |
| VC   | Voice conversion              |
